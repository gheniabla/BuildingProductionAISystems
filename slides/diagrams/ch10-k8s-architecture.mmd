flowchart TD
    Ingress["Ingress Controller\n(NGINX / Traefik / ALB)"]:::gateway

    Ingress --> Svc

    subgraph NS ["NAMESPACE: ai-prod"]
        Svc["SERVICE: api\n(ClusterIP / LoadBalancer)"]:::service

        Svc --> Pod1 & Pod2 & Pod3

        subgraph Deploy ["DEPLOYMENT: ai-api"]
            Pod1["Pod 1\nAPI Container"]:::client
            Pod2["Pod 2\nAPI Container"]:::client
            Pod3["Pod 3\nAPI Container"]:::client
        end

        subgraph Workers ["DEPLOYMENT: celery-worker"]
            W1["Worker 1"]:::service
            W2["Worker 2"]:::service
        end

        subgraph GPU ["STATEFULSET: vllm-gpu"]
            VLLM["vLLM Pod - GPU Node\nNVIDIA A100 80GB\nModel: Llama-2-70b\nPVC: model-storage 500GB"]:::external
        end

        CM["ConfigMap\napp-config, prompts"]:::data
        Secret["Secret\napi-keys, db-creds"]:::data
        HPA["HPA\nmin: 2, max: 10\ntarget: 70% CPU"]:::observability
    end

    HPA -. scales .-> Deploy

    classDef client fill:#3B82F6,stroke:#1D4ED8,color:#FFFFFF
    classDef gateway fill:#EF4444,stroke:#B91C1C,color:#FFFFFF
    classDef service fill:#4F46E5,stroke:#3730A3,color:#FFFFFF
    classDef data fill:#10B981,stroke:#047857,color:#FFFFFF
    classDef external fill:#F59E0B,stroke:#D97706,color:#FFFFFF
    classDef observability fill:#8B5CF6,stroke:#6D28D9,color:#FFFFFF
