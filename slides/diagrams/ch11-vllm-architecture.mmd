flowchart TD
    subgraph API ["API Layer"]
        EP["OpenAI-compatible endpoints\n/v1/completions\n/v1/chat/completions"]:::gateway
    end

    API --> SCHED

    subgraph SCHED ["Scheduler & Batching"]
        CB["Continuous Batching\nNew requests start as soon as old ones finish\n\nTraditional: slots idle until batch completes\nContinuous: slots reused immediately"]:::service
    end

    SCHED --> PAGED

    subgraph PAGED ["PagedAttention Memory Manager"]
        KV["KV Cache Management\n\nTraditional: pre-allocated, wasted space\nPagedAttention: dynamic page allocation/freeing\nMemory pages shared across requests"]:::observability
    end

    PAGED --> GPUS

    subgraph GPUS ["GPU Execution"]
        G0["GPU 0\nTensor Parallel"]:::external
        G1["GPU 1\nTensor Parallel"]:::external
        G2["GPU 2\nTensor Parallel"]:::external
        G3["GPU 3\nTensor Parallel"]:::external
    end

    classDef client fill:#3B82F6,stroke:#1D4ED8,color:#FFFFFF
    classDef gateway fill:#EF4444,stroke:#B91C1C,color:#FFFFFF
    classDef service fill:#4F46E5,stroke:#3730A3,color:#FFFFFF
    classDef data fill:#10B981,stroke:#047857,color:#FFFFFF
    classDef external fill:#F59E0B,stroke:#D97706,color:#FFFFFF
    classDef observability fill:#8B5CF6,stroke:#6D28D9,color:#FFFFFF
